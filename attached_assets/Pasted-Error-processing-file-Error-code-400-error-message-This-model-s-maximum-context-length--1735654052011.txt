Error processing file: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 184059 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}

Detailed error: Traceback (most recent call last): File "/home/runner/ExcelMetaExtractor/main.py", line 86, in main metadata = extractor.extract_all_metadata() ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/excel_metadata_extractor.py", line 264, in extract_all_metadata sheets_metadata = self.get_sheet_metadata() ^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/excel_metadata_extractor.py", line 240, in get_sheet_metadata regions = self.detect_regions(sheet) ^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/excel_metadata_extractor.py", line 170, in detect_regions region_analysis = self.openai_helper.analyze_region_type(json.dumps({ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/openai_helper.py", line 32, in analyze_region_type response = self.client.chat.completions.create( ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/.pythonlibs/lib/python3.11/site-packages/openai/_utils/_utils.py", line 275, in wrapper return func(*args, **kwargs) ^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/.pythonlibs/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 859, in create return self._post( ^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/.pythonlibs/lib/python3.11/site-packages/openai/_base_client.py", line 1280, in post return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/.pythonlibs/lib/python3.11/site-packages/openai/_base_client.py", line 957, in request return self._request( ^^^^^^^^^^^^^^ File "/home/runner/ExcelMetaExtractor/.pythonlibs/lib/python3.11/site-packages/openai/_base_client.py", line 1061, in _request raise self._make_status_error_from_response(err.response) from None openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 184059 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}