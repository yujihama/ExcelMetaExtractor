import os
from openai import OpenAI
from typing import Dict, Any, Union, List
import json
import streamlit as st


class OpenAIHelper:

    def __init__(self):
        self.client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
        self.model = "gpt-4o"

    def summarize_region(self, region: Dict[str, Any]) -> str:
        """Generate a summary for a region based on its content"""
        try:
            if region["regionType"] == "table":
                # „ÉÜ„Éº„Éñ„É´Áî®„ÅÆ„Çµ„Éû„É™„ÉºÁîüÊàê
                cells = region.get("sampleCells", [])
                header_structure = region.get("headerStructure", {})
                prompt = f"""‰ª•‰∏ã„ÅÆExcel„ÉÜ„Éº„Éñ„É´È†òÂüü„ÅÆÂÜÖÂÆπ„ÇíÁ∞°ÊΩî„Å´Ë¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
                „Éò„ÉÉ„ÉÄ„ÉºÊßãÈÄ†: {json.dumps(header_structure, ensure_ascii=False)}
                „Éá„Éº„Çø„Çµ„É≥„Éó„É´: {json.dumps(cells[:2], ensure_ascii=False)}
                """
            else:
                # „Åù„ÅÆ‰ªñ„ÅÆÈ†òÂüüÁî®„ÅÆ„Çµ„Éû„É™„ÉºÁîüÊàê
                prompt = f"""‰ª•‰∏ã„ÅÆExcelÈ†òÂüü„ÅÆÂÜÖÂÆπ„ÇíÁ∞°ÊΩî„Å´Ë¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
                È†òÂüü„Çø„Ç§„Éó: {region["regionType"]}
                ÁØÑÂõ≤: {region["range"]}
                ÂÜÖÂÆπ: {json.dumps(region, ensure_ascii=False)[:200]}
                """

            response = self.client.chat.completions.create(model=self.model,
                                                           messages=[{
                                                               "role":
                                                               "user",
                                                               "content":
                                                               prompt
                                                           }],
                                                           max_tokens=150)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error generating summary: {str(e)}")
            return "„Çµ„Éû„É™„Éº„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü"

    def analyze_region_type(self, region_data: str) -> Dict[str, Any]:
        """Analyze region type using LLM with size limits"""
        data = json.loads(region_data)
        sample_data = {
            "cells": data["cells"][:5],
            "mergedCells": data.get("mergedCells", [])[:3]
        }

        prompt = f"""Analyze the following Excel region sample data and determine:
1. The type of region (table, text, chart, image)
2. If it contains a table title or document heading
3. The purpose or meaning of the content, considering Japanese text patterns

Region sample data (first few rows/cells):
{json.dumps(sample_data, indent=2)}

Consider Japanese text patterns like:
- Table titles („Äá„Äá‰∏ÄË¶ß, ‚ñ≥‚ñ≥Ë°®, ‚ñ°‚ñ°„É™„Çπ„Éà)
- Section headings (Â§ßÈ†ÖÁõÆ, ‰∏≠È†ÖÁõÆ, Â∞èÈ†ÖÁõÆ)
- Data categories (Âå∫ÂàÜ, ÂàÜÈ°û, Á®ÆÂà•)

Respond in JSON format:
{{
    "regionType": "table" or "text" or "chart" or "image",
    "title": {{
        "detected": boolean,
        "content": string or null,
        "row": number or null
    }},
    "characteristics": [string],
    "purpose": string,
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"},
                max_tokens=1000)
            with st.expander("üîç Analyzed Region Data"):
                st.write(prompt)
                st.write(response.choices[0].message.content)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_region_type: {str(e)}")
            return json.dumps({
                "regionType": "unknown",
                "title": {
                    "detected": False,
                    "content": None,
                    "row": None
                },
                "characteristics": [],
                "purpose": "Error in analysis",
                "confidence": 0
            })

    def analyze_table_structure_with_hints(self, data: str) -> Dict[str, Any]:
        """Analyze table structure using LLM with hints about potential header rows"""
        try:
            prompt = f"""‰∏é„Åà„Çâ„Çå„Åü„ÉÜ„Éº„Éñ„É´„ÅÆ„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Å®„Éò„ÉÉ„ÉÄ„ÉºË°å„ÅÆÂÄôË£ú„Åã„Çâ„ÄÅ‰ª•‰∏ã„ÇíÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
1. „ÉÜ„Éº„Éñ„É´„ÅÆ„Éò„ÉÉ„ÉÄ„ÉºÊßãÈÄ†ÔºàÂçò‰∏ÄË°å„ÅÆ„Éò„ÉÉ„ÉÄ„Éº/Ë§áÂêà„Éò„ÉÉ„ÉÄ„ÉºÔºâ
2. „Éò„ÉÉ„ÉÄ„ÉºË°å„ÅÆÊ≠£Á¢∫„Å™‰ΩçÁΩÆÔºàË§áÂêà„Éò„ÉÉ„ÉÄ„Éº„ÅÆÂ†¥Âêà„ÅØË§áÊï∞Ë°åÂõûÁ≠îÔºâ
3. ÂêÑÂàó„ÅÆÁ®ÆÈ°û„Å®ÊÑèÂë≥

„Éá„Éº„Çø:
{data}

„Éò„ÉÉ„ÉÄ„Éº„ÅÆÂà§Êñ≠Âü∫Ê∫ñ:
- ‰∏ÄË¶ßË°®„ÇÑ„Éû„Çπ„ÇøÁ≠â„ÅÆË°®È°å
- ÂàóË¶ãÂá∫„Åó„ÅÆÈöéÂ±§ÊßãÈÄ†
- „Éá„Éº„ÇøÂàÜÈ°û„ÇÑÂçò‰Ωç„ÅÆË®òËºâ
- ÁµêÂêà„Çª„É´„ÅÆ‰ΩøÁî®„Éë„Çø„Éº„É≥

JSONÂΩ¢Âºè„ÅßËøîÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
{{
    "headerType": "single" „Åæ„Åü„ÅØ "multiple" „Åæ„Åü„ÅØ "none",
    "headerRows": [Ë°åÁï™Âè∑„ÅÆ„É™„Çπ„Éà],
    "confidence": 0-1„ÅÆÊï∞ÂÄ§
}}"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"})
            with st.expander("üîç Analyzed Table Structure"):
                st.write(prompt)
                st.write(response.choices[0].message.content)

            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_table_structure_with_hints: {str(e)}")
            return json.dumps({
                "headerType": "none",
                "headerRows": [],
                "confidence": 0
            })

    def analyze_table_structure(self, cells_data: str,
                                merged_cells) -> Dict[str, Any]:
        """Analyze table structure using LLM with size limits"""
        # data = json.loads(cells_data)
        # if isinstance(data, list):
        #     sample_data = data[:5]
        # else:
        #     sample_data = data

        prompt = f"""Analyze the following Excel cells sample data and determine:
1. Title row detection (‰æã: Â£≤‰∏äÂÆüÁ∏æË°®, ÂïÜÂìÅ„Éû„Çπ„Çø‰∏ÄË¶ß)
2. Header structure (single/multiple header rows)

„Éò„ÉÉ„ÉÄ„Éº„ÅÆÂà§Êñ≠Âü∫Ê∫ñ:
- ‰∏ÄË¶ßË°®„ÇÑ„Éû„Çπ„ÇøÁ≠â„ÅÆË°®È°å
- ÂàóË¶ãÂá∫„Åó„ÅÆÈöéÂ±§ÊßãÈÄ†
- „Éá„Éº„ÇøÂàÜÈ°û„ÇÑÂçò‰Ωç„ÅÆË®òËºâ
- ÁµêÂêà„Çª„É´„ÅÆ‰ΩøÁî®
- ÂêàË®àË°å„ÇÑÁ∑èË®à„ÄÅÂ∞èË®à„ÅÆË°å„ÅØ„Éò„ÉÉ„ÉÄ„Éº„Å´Âê´„ÇÅ„Å™„ÅÑ„Åì„Å®

Sample data(Refer to the rows and columns (row and col) for accurate interpretation of the structure):

{cells_data}

„Åæ„Åü„ÄÅ‰ª•‰∏ã„ÅÆ„Çª„É´„ÅØÁµêÂêà„Åï„Çå„Å¶„ÅÑ„Çã„ÅÆ„Åß„Éò„ÉÉ„ÉÄ„ÉºÊ§úÁü•„ÅÆÂèÇËÄÉ„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
{merged_cells}

Respond in JSON format:
{{
    "titleRow": {{
        "detected": boolean,
        "content": string or null,
        "row": number or null
    }},
    "headerStructure": {{
        "type": "single" or "multiple" or "none",
        "rows": [row_indices]
        "reason": if you ansewered "multiple", please explain why
    }},
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt,
                }],
                response_format={"type": "json_object"},
                temperature=0)
            #max_tokens=1000)
            with st.expander("üîç Analyzed Table Structure"):
                st.write(prompt)
                st.write(response.choices[0].message.content)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_table_structure: {str(e)}")
            return json.dumps({
                "titleRow": {
                    "detected": False,
                    "content": None,
                    "row": None
                },
                "headerStructure": {
                    "type": "none",
                    "rows": [],
                    "hierarchy": None
                },
                "columns": [],
                "confidence": 0
            })

    def analyze_text_block(self, text_content: str) -> Dict[str, Any]:
        """Analyze text block content using LLM with size limits"""
        sample_text = text_content[:1000]

        prompt = f"""Analyze the following text content from an Excel sheet:
1. Type of content (Ë≠∞‰∫ãÈå≤, „Ç≥„É°„É≥„Éà, Ë™¨ÊòéÊñá„Å™„Å©)
2. Importance level
3. Key points or takeaways
4. Consider Japanese text patterns and business terms

Text sample:
{sample_text}

Respond in JSON format:
{{
    "contentType": string,
    "importance": "high" or "medium" or "low",
    "summary": string,
    "keyPoints": [string],
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"},
                max_tokens=1000)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_text_block: {str(e)}")
            return json.dumps({
                "contentType": "unknown",
                "importance": "low",
                "summary": "Error in analysis",
                "keyPoints": [],
                "confidence": 0
            })

    def analyze_chart(self, chart_elements: str) -> Dict[str, Any]:
        """Analyze chart elements using LLM with size limits"""
        sample_elements = chart_elements[:1000]

        prompt = f"""Analyze the following chart elements from Excel:
1. Type of visualization
2. Purpose and key message
3. Data relationships
4. Consider Japanese chart titles and labels

Chart elements:
{sample_elements}

Respond in JSON format:
{{
    "chartType": string,
    "purpose": string,
    "dataRelations": [string],
    "suggestedUsage": string,
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"},
                max_tokens=1000)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_chart: {str(e)}")
            return json.dumps({
                "chartType": "unknown",
                "purpose": "Error in analysis",
                "dataRelations": [],
                "suggestedUsage": "Error in analysis",
                "confidence": 0
            })

    def analyze_merged_cells(self, merged_cells_data: str) -> Dict[str, Any]:
        """Analyze merged cells pattern using LLM with size limits"""
        sample_data = merged_cells_data[:1000]

        prompt = f"""Analyze the following merged cells pattern:
1. Purpose of merging (Ë¶ãÂá∫„Åó, „Ç∞„É´„Éº„ÉóÂåñ, Êï¥ÂΩ¢„Å™„Å©)
2. Structural implications
3. Consider Japanese organizational patterns

Merged cells data:
{sample_data}

Respond in JSON format:
{{
    "pattern": string,
    "purpose": string,
    "structureType": "header" or "grouping" or "formatting" or "other",
    "implications": [string],
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"},
                max_tokens=1000)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_merged_cells: {str(e)}")
            return json.dumps({
                "pattern": "unknown",
                "purpose": "Error in analysis",
                "structureType": "other",
                "implications": [],
                "confidence": 0
            })
