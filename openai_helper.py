import os
from openai import OpenAI
from typing import Dict, Any, Union, List
import json
import streamlit as st
from dotenv import load_dotenv


class OpenAIHelper:

    def __init__(self):
        load_dotenv()
        self.client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
        self.model = "gpt-4o"

    def summarize_region(self, region: Dict[str, Any]) -> str:
        """Generate a summary for a region based on its content"""
        try:
            if region["regionType"] == "table":
                # ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                cells = region.get("sampleCells", [])
                header_structure = region.get("headerStructure", {})
                prompt = f"""ä»¥ä¸‹ã®Excelãƒ†ãƒ¼ãƒ–ãƒ«é ˜åŸŸãŒä½•ã«ã¤ã„ã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„:
                ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ : {json.dumps(header_structure, ensure_ascii=False)}
                ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«: {json.dumps(cells[:2], ensure_ascii=False)}
                """
            elif region["regionType"] == "chart":
                # ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                prompt = f"""ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ãŒä½•ã«ã¤ã„ã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„:
                ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—: {region["chartType"]}
                ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {region["series"][0]["data_range"]}
                å†…å®¹: {region["chart_data_json"]}
                """
            elif region["regionType"] == "image":
                # ç”»åƒç”¨ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆï¼ˆGPT-4ã®åˆ†æçµæœã‚’å«ã‚€ï¼‰
                gpt4o_analysis = region.get("gpt4o_analysis", {})
                prompt = f"""ä»¥ä¸‹ã®ç”»åƒã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„:
                ç”»åƒã®ç¨®é¡: {gpt4o_analysis.get("imageType", "ä¸æ˜")}
                å†…å®¹: {gpt4o_analysis.get("content", "ä¸æ˜")}
                ç‰¹å¾´: {", ".join(gpt4o_analysis.get("features", []))}
                ä½ç½®: {region["range"]}
                åå‰: {region.get("name", "")}
                èª¬æ˜: {region.get("description", "")}
                """
            elif region["regionType"] == "shape":
                # å›³å½¢ç”¨ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                prompt = f"""ä»¥ä¸‹ã®Excelã®å›³å½¢ãŒä½•ã«ã¤ã„ã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„:
                å†…å®¹: {json.dumps(region, ensure_ascii=False)}
                """
            else:
                # ãã®ä»–ã®é ˜åŸŸç”¨ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                prompt = f"""ä»¥ä¸‹ã®Excelé ˜åŸŸãŒä½•ã«ã¤ã„ã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‹ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„:
                é ˜åŸŸã‚¿ã‚¤ãƒ—: {region["regionType"]}
                ç¯„å›²: {region["range"]}
                å†…å®¹: {json.dumps(region, ensure_ascii=False)[:200]}
                """

            response = self.client.chat.completions.create(model=self.model,
                                                           messages=[{
                                                               "role":
                                                               "user",
                                                               "content":
                                                               prompt
                                                           }],
                                                           max_tokens=1000)
            # with st.expander("LLM_Summary"):
            #     st.write(prompt)
            #     st.write(response.choices[0].message.content)

            return response.choices[0].message.content
        except Exception as e:
            print(f"Error generating summary: {str(e)}")
            return "ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"

    def analyze_region_type(self, region_data: str) -> Dict[str, Any]:
        """Analyze region type using LLM with size limits"""
        data = json.loads(region_data)
        sample_data = {
            "cells": data["cells"][:5],
            "mergedCells": data.get("mergedCells", [])[:3]
        }

        prompt = f"""Analyze the following Excel region sample data and determine:
1. The type of region (table, text, chart, image)
2. If it contains a table title or document heading
3. The purpose or meaning of the content, considering Japanese text patterns

Region sample data (first few rows/cells):
{json.dumps(sample_data, indent=2)}

Consider Japanese text patterns like:
- Table titles (ä¸€è¦§è¡¨, é›†è¨ˆè¡¨, ãƒªã‚¹ãƒˆ)
- Section headings (å¤§é …ç›®, ä¸­é …ç›®, å°é …ç›®)
- Data categories (åŒºåˆ†, åˆ†é¡, ç¨®åˆ¥)

Respond in JSON format:
{{
    "regionType": "table" or "text" or "chart" or "image",
    "title": {{
        "detected": boolean,
        "content": string or null,
        "row": number or null
    }},
    "characteristics": [string],
    "purpose": string,
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                response_format={"type": "json_object"},
                max_tokens=2000)
            # with st.expander("ğŸ” Analyzed Region Data"):
            #     st.write(prompt)
            #     st.write(response.choices[0].message.content)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_region_type: {str(e)}")
            return json.dumps({
                "regionType": "unknown",
                "title": {
                    "detected": False,
                    "content": None,
                    "row": None
                },
                "characteristics": [],
                "purpose": "Error in analysis",
                "confidence": 0
            })

    def analyze_table_structure(self, cells_data: str,
                                merged_cells) -> Dict[str, Any]:
        """Analyze table structure using LLM with size limits"""
        # data = json.loads(cells_data)
        # if isinstance(data, list):
        #     sample_data = data[:5]
        # else:
        #     sample_data = data

        prompt = f"""Analyze the following Excel cells sample data and determine:
1. Title row detection (ä¾‹: å£²ä¸Šå®Ÿç¸¾è¡¨, å•†å“ãƒã‚¹ã‚¿ä¸€è¦§)
2. Header structure (single/multiple header rows)

ãƒ˜ãƒƒãƒ€ãƒ¼ã®åˆ¤æ–­åŸºæº–:
- ä¸€è¦§è¡¨ã‚„ãƒã‚¹ã‚¿ç­‰ã®è¡¨é¡Œ
- åˆ—è¦‹å‡ºã—ã®éšå±¤æ§‹é€ 
- ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã‚„å˜ä½ã®è¨˜è¼‰
- çµåˆã‚»ãƒ«ã®ä½¿ç”¨
- åˆè¨ˆè¡Œã‚„ç·è¨ˆã€å°è¨ˆã®è¡Œã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã‚ãªã„ã“ã¨

Sample data(Refer to the rows and columns (row and col) for accurate interpretation of the structure):

{cells_data}

ã¾ãŸã€ä»¥ä¸‹ã®ã‚»ãƒ«ã¯çµåˆã•ã‚Œã¦ã„ã‚‹ã®ã§ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œçŸ¥ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚
{merged_cells}

Respond in JSON format:
{{
    "titleRow": {{
        "detected": boolean,
        "content": string or null,
        "row": number or null
    }},
    "headerStructure": {{
        "type": "single" or "multiple" or "none",
        "rows": [row_indices]
        "reason": if you ansewered "multiple", please explain why
    }},
    "confidence": number
}}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt,
                }],
                response_format={"type": "json_object"},
                temperature=0)
            #max_tokens=1000)
            # with st.expander("ğŸ” Analyzed Table Structure"):
            #     st.write(prompt)
            #     st.write(response.choices[0].message.content)
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error in analyze_table_structure: {str(e)}")
            return json.dumps({
                "titleRow": {
                    "detected": False,
                    "content": None,
                    "row": None
                },
                "headerStructure": {
                    "type": "none",
                    "rows": [],
                    "hierarchy": None
                },
                "columns": [],
                "confidence": 0
            })

    def generate_sheet_summary(self, sheet_data: Dict[str, Any]) -> str:
        """Generate a summary for an entire sheet using LLM with region summaries already available."""
        try:
            regions = sheet_data.get('regions', [])
            region_summaries = []

            for region in regions:
                if "summary" in region:
                    region_type = region.get("regionType", "unknown")
                    region_range = region.get("range", "")
                    summary = region.get("summary", "")
                    region_summaries.append(
                        f"{region_type} ({region_range}): {summary}")

            prompt = f"""ä»¥ä¸‹ã¯Excelã‚·ãƒ¼ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã§ã™ã€‚å„é ˜åŸŸã®æƒ…å ±ã‚’ã‚ˆãç†è§£ã—ãŸã†ãˆã§è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å®¢è¦³çš„ã«æ¨æ¸¬ã‚’äº¤ãˆãšã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚:
ã‚·ãƒ¼ãƒˆå: {sheet_data.get('sheetName', '')}
æ¤œå‡ºã•ã‚ŒãŸé ˜åŸŸæ•°: {len(regions)}

å„é ˜åŸŸã®è¦ç´„:
{"\n".join(region_summaries)}

ä»¥ä¸‹ã®ç‚¹ã«æ³¨ç›®ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„:
- ã‚·ãƒ¼ãƒˆã®ä¸»ãªç›®çš„ã‚„å†…å®¹
- å«ã¾ã‚Œã‚‹ä¸»è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚„å›³å½¢
- å„é ˜åŸŸã®é–¢ä¿‚æ€§

ç‰¹ã«ä»¥ä¸‹ã«ã¯ã‚ˆãæ³¨æ„ã—ã¦ãã ã•ã„:
- è¡¨/ã‚°ãƒ©ãƒ•ã®è¦‹ãŸç›®ã‚„å†…å®¹ã®ç‰¹å¾´ã‚’ã—ã£ã‹ã‚Šã¨ã‚‰ãˆã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚
- sheetã«å«ã¾ã‚Œã¦ã„ãªã„æƒ…å ±ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- æ¨æ¸¬ã§è¨˜è¼‰ã—ãªã„ã§ãã ã•ã„ã€‚
"""
            response = self.client.chat.completions.create(model=self.model,
                                                           messages=[{
                                                               "role":
                                                               "user",
                                                               "content":
                                                               prompt
                                                           }],
                                                           max_tokens=2000)

            return response.choices[0].message.content
        except Exception as e:
            print(f"Error generating sheet summary: {str(e)}")
            return "ã‚·ãƒ¼ãƒˆã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"

    def analyze_image_with_gpt4o(self, base64_image: str) -> Dict[str, Any]:
        """GPT-4oã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’åˆ†æ"""
        try:
            prompt = """ã“ã®ç”»åƒã«ã¤ã„ã¦ä»¥ä¸‹ã®ç‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š
1. ç”»åƒã®ç¨®é¡é¡ï¼ˆã‚°ãƒ©ãƒ•ã€å›³è¡¨ã€å†™çœŸãªã©ï¼‰
2. ä¸»ãªå†…å®¹ã‚„ç›®çš„
3. ç‰¹å¾´çš„ãªè¦ç´ 

ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{
    "imageType": "graph/table/photo/other",
    "content": "ç”»åƒã®å†…å®¹ã®èª¬æ˜",
    "features": ["ç‰¹å¾´1", "ç‰¹å¾´2", ...]
}
"""
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role":
                    "user",
                    "content": [{
                        "type": "text",
                        "text": prompt
                    }, {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }]
                }],
                response_format={"type": "json_object"},
                max_tokens=2000)
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"Error analyzing image with GPT-4o: {str(e)}")
            return {
                "imageType": "unknown",
                "content": "ç”»åƒåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ",
                "features": []
            }
